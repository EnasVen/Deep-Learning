{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer and pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Some ThING to eat !', 'some thing to drink .', 'some thing']\n",
      "========\n",
      "OrderedDict([('some', 3), ('thing', 3), ('to', 2), ('eat', 1), ('drink', 1)])\n",
      "{'some': 1, 'thing': 2, 'to': 3, 'eat': 4, 'drink': 5}\n",
      "========\n",
      "[[1, 2, 3, 4], [1, 2, 3, 5], [1, 2]]\n",
      "found 5 unique tokens\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "text1 = 'Some ThING to eat !'\n",
    "text2 = 'some thing to drink .'\n",
    "text3 = 'some thing'\n",
    "texts=[text1,text2, text3]\n",
    "print(texts)\n",
    "print('========')\n",
    "tokenizer = Tokenizer(num_words=100) #num_words:None或整数,处理的最大单词数量。少于此数的单词丢掉\n",
    "tokenizer.fit_on_texts(texts)\n",
    "print(tokenizer.word_counts) \n",
    "print(tokenizer.word_index) \n",
    "\n",
    "print('========')\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index\n",
    "print(sequences)\n",
    "print('found {} unique tokens'.format(len(word_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4 0 0 0 0]\n",
      " [1 2 3 5 0 0 0 0]\n",
      " [1 2 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# 把向量長度補齊\n",
    "pad_seq = pad_sequences(sequences, maxlen=8, padding='post')\n",
    "print(pad_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, SimpleRNN\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# load mnist dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the number of labels\n",
    "num_labels = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to one-hot vector\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize and normalize\n",
    "image_size = x_train.shape[1]\n",
    "x_train = np.reshape(x_train,[-1, image_size, image_size])\n",
    "x_test = np.reshape(x_test,[-1, image_size, image_size])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131328"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "256*256*2+256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_23 (SimpleRNN)    (None, 28, 256)           72960     \n",
      "_________________________________________________________________\n",
      "simple_rnn_24 (SimpleRNN)    (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 206,858\n",
      "Trainable params: 206,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# network parameters\n",
    "input_shape = (image_size, image_size)\n",
    "batch_size = 128\n",
    "units = 256\n",
    "\n",
    "# model is RNN with 256 units, input is 28-dim vector 28 timesteps\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "model = Sequential()\n",
    "# input_ shape = (timesteps, input_dim)\n",
    "model.add(SimpleRNN(units=units,\n",
    "                    input_shape=input_shape,return_sequences=True)   )\n",
    "model.add(SimpleRNN(units=256, return_sequences=False ) )\n",
    "# model.add(Bidirectional(tf.keras.layers.LSTM( (256,256)))\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72960"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "256*256+28*256+256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.18.5'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 80)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.6503 - accuracy: 0.8250\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.2813 - accuracy: 0.9183\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.2103 - accuracy: 0.9390\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.1714 - accuracy: 0.9503\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.1435 - accuracy: 0.9585\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.1292 - accuracy: 0.9627\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.1146 - accuracy: 0.9671\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.1037 - accuracy: 0.9694\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0965 - accuracy: 0.9723\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0881 - accuracy: 0.9748\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0821 - accuracy: 0.9760\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0772 - accuracy: 0.9776\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0720 - accuracy: 0.9790\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0680 - accuracy: 0.9802\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0637 - accuracy: 0.9811\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0610 - accuracy: 0.9825\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0588 - accuracy: 0.9829\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0541 - accuracy: 0.9843\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0540 - accuracy: 0.9837\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 6s 14ms/step - loss: 0.0506 - accuracy: 0.9854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f15c4ef730>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss function for one-hot vector\n",
    "# use of sgd optimizer\n",
    "# accuracy is good metric for classification tasks\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "# train the network\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 98.0%\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(x_test,\n",
    "                        y_test,\n",
    "                        batch_size=batch_size,\n",
    "                        verbose=0)\n",
    "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "db_train = db_train.shuffle(1000).batch(batch_size, drop_remainder=True)\n",
    "db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "db_test = db_test.batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_len =32\n",
    "\n",
    "class MyRNN(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, units):\n",
    "        super(MyRNN, self).__init__()\n",
    "\n",
    "        # [b, 64]\n",
    "        self.state = [tf.zeros([batch_size, units])]\n",
    "        # self.state1 = [tf.zeros([batchsz, units])]\n",
    "        # transform text to embedding representation\n",
    "        # [b, 80] => [b, 80, 32]\n",
    "        self.embedding = tf.keras.layers.Embedding(total_words, embedding_len,\n",
    "                                          input_length=max_review_len)\n",
    "        # [b, 80, 32] , h_dim: 64\n",
    "        # RNN: cell1 ,cell2, cell3\n",
    "        # SimpleRNN\n",
    "        self.rnn_cell = tf.keras.layers.SimpleRNNCell(units, dropout=0.2)\n",
    "        # self.rnn_cell1 = layers.SimpleRNNCell(units, dropout=0.5)\n",
    "        # fc, [b, 80, 32] => [b, 64] => [b, 1]\n",
    "        self.fc= tf.keras.layers.Dense(1) # 二元分類也可以輸出層只給1個神經元，但後面的loss要用binary_cross_entropy\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # [b, 80]\n",
    "        x = inputs\n",
    "        # embedding: [b, 80] => [b, 80, 32]\n",
    "        x = self.embedding(x)\n",
    "        # rnn cell compute\n",
    "        # [b, 80, 32] => [b, 64]\n",
    "        state = self.state\n",
    "        # state1 = self.state1\n",
    "        for word in tf.unstack(x, axis=1): # word: [b, 32]\n",
    "            # h1 = x*wxh+h0*whh\n",
    "            # out: [b, 64]\n",
    "            out, state = self.rnn_cell(word, state, training)\n",
    "        # out: [b, 64] => [b, 1]\n",
    "        x = self.fc(out)\n",
    "        # p(y is pos|x)\n",
    "        prob = tf.sigmoid(x)\n",
    "\n",
    "        return prob\n",
    "\n",
    "model = MyRNN(64) \n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "781/781 [==============================] - 4s 5ms/step - loss: 0.5939 - accuracy: 0.6612 - val_loss: 0.4388 - val_accuracy: 0.8050\n",
      "Epoch 2/5\n",
      "781/781 [==============================] - 3s 4ms/step - loss: 0.3700 - accuracy: 0.8389 - val_loss: 0.4240 - val_accuracy: 0.8220\n",
      "Epoch 3/5\n",
      "781/781 [==============================] - 3s 4ms/step - loss: 0.2639 - accuracy: 0.8932 - val_loss: 0.4769 - val_accuracy: 0.8154\n",
      "Epoch 4/5\n",
      "781/781 [==============================] - 4s 5ms/step - loss: 0.1814 - accuracy: 0.9309 - val_loss: 0.5956 - val_accuracy: 0.7567\n",
      "Epoch 5/5\n",
      "781/781 [==============================] - 3s 4ms/step - loss: 0.1196 - accuracy: 0.9554 - val_loss: 0.6436 - val_accuracy: 0.7958\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(db_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=512,\n",
    "                    validation_data=db_test,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
