{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def prepare_data(data_file_name):\n",
    "    \"\"\"\n",
    "    Responsible for cleaning the data file provided from the UCI machine\n",
    "    learning repository here: http://archive.ics.uci.edu/ml/datasets/Mushroom.\n",
    "    The function then produces two CSV files appropriately formatted to be\n",
    "    used in TensorFlow where the CSV files split with respect to\n",
    "    training and testing data.\n",
    "    \"\"\"\n",
    "\n",
    "    # The header is formed from the 'agaricus-lepiota.name' file found on\n",
    "    # http://archive.ics.uci.edu/ml/datasets/Mushroom\n",
    "    header = ['class', 'cap_shape', 'cap_surface',\n",
    "              'cap_color', 'bruises', 'odor', 'gill_attachment',\n",
    "              'gill_spacing', 'gill_size', 'gill_color', 'stalk_shape',\n",
    "              'stalk_root', 'stalk_surface_above_ring',\n",
    "              'stalk_surface_below_ring', 'stalk_color_above_ring',\n",
    "              'stalk_color_below_ring', 'veil_type', 'veil_color',\n",
    "              'ring_number', 'ring_type', 'spore_print_color',\n",
    "              'population', 'habitat']\n",
    "    df = pd.read_csv(data_file_name, sep=',', names=header)\n",
    "\n",
    "    # Entries with a '?' indicate a missing piece of data, and\n",
    "    # these entries are dropped from our dataset.\n",
    "    df.replace('?', np.nan, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # The class of poisonous or edible is indicated in the data as\n",
    "    # either 'p' or 'e' respectively. We require that this is numeric,\n",
    "    # and therefore use '0' to indicate poisonous (or not edible) and\n",
    "    # '1' to indicate edible.\n",
    "    df['class'].replace('p', 0, inplace=True)\n",
    "    df['class'].replace('e', 1, inplace=True)\n",
    "\n",
    "    # Since we are dealing with non-numeric feature data, or in other\n",
    "    # words, categorical data, we need to replace these with numerical\n",
    "    # equivalents. Pandas has a nice function called \"get_dummies\" that\n",
    "    # performs this task.\n",
    "    cols_to_transform = header[1:]\n",
    "    df = pd.get_dummies(df, columns=cols_to_transform)\n",
    "\n",
    "    # We can now split the data into two separate data frames,\n",
    "    # one for training, which will constitute the bulk of the\n",
    "    # data, and one for testing.\n",
    "    df_train, df_test = train_test_split(df, test_size=0.1)\n",
    "\n",
    "    # Determine the number of rows and columns in each of the\n",
    "    # data frames.\n",
    "    num_train_entries = df_train.shape[0]\n",
    "    num_train_features = df_train.shape[1] - 1\n",
    "\n",
    "    num_test_entries = df_test.shape[0]\n",
    "    num_test_features = df_test.shape[1] - 1\n",
    "\n",
    "    # The data frames are written as a temporary CSV file, as we still\n",
    "    # need to modify the header row to include the number of rows and\n",
    "    # columns present in the training and testing CSV files.\n",
    "    df_train.to_csv('mushroom_train.csv', index=False)\n",
    "    df_test.to_csv('mushroom_test.csv', index=False)\n",
    "\n",
    "    \n",
    "MUSHROOM_DATA_FILE = \"agaricus-lepiota.data\"\n",
    "\n",
    "# Prepare the mushroom data for TensorFlow by\n",
    "# creating two train / test CSV files.\n",
    "prepare_data(MUSHROOM_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class  cap_shape_b  cap_shape_c  cap_shape_f  cap_shape_k  cap_shape_s  \\\n",
      "0      0            0            0            0            0            0   \n",
      "1      0            0            0            0            0            0   \n",
      "2      0            0            0            1            0            0   \n",
      "3      1            0            0            0            0            0   \n",
      "4      1            0            0            1            0            0   \n",
      "\n",
      "   cap_shape_x  cap_surface_f  cap_surface_g  cap_surface_s  ...  \\\n",
      "0            1              0              0              0  ...   \n",
      "1            1              1              0              0  ...   \n",
      "2            0              1              0              0  ...   \n",
      "3            1              1              0              0  ...   \n",
      "4            0              0              0              0  ...   \n",
      "\n",
      "   population_n  population_s  population_v  population_y  habitat_d  \\\n",
      "0             0             0             0             1          0   \n",
      "1             0             0             0             1          0   \n",
      "2             0             0             1             0          1   \n",
      "3             0             0             0             1          1   \n",
      "4             0             0             0             1          0   \n",
      "\n",
      "   habitat_g  habitat_l  habitat_m  habitat_p  habitat_u  \n",
      "0          0          0          0          1          0  \n",
      "1          0          0          0          1          0  \n",
      "2          0          0          0          0          0  \n",
      "3          0          0          0          0          0  \n",
      "4          0          0          0          1          0  \n",
      "\n",
      "[5 rows x 99 columns]\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('mushroom_train.csv')\n",
    "print(df_train.head())\n",
    "\n",
    "train_label = np.array(df_train['class'])\n",
    "train_data =  np.array(df_train.drop('class', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class  cap_shape_b  cap_shape_c  cap_shape_f  cap_shape_k  cap_shape_s  \\\n",
      "0      0            0            0            0            0            0   \n",
      "1      1            0            0            1            0            0   \n",
      "2      1            0            0            1            0            0   \n",
      "3      0            0            0            1            0            0   \n",
      "4      1            0            0            1            0            0   \n",
      "\n",
      "   cap_shape_x  cap_surface_f  cap_surface_g  cap_surface_s  ...  \\\n",
      "0            1              0              0              0  ...   \n",
      "1            0              1              0              0  ...   \n",
      "2            0              1              0              0  ...   \n",
      "3            0              0              0              0  ...   \n",
      "4            0              1              0              0  ...   \n",
      "\n",
      "   population_n  population_s  population_v  population_y  habitat_d  \\\n",
      "0             0             0             0             1          0   \n",
      "1             0             1             0             0          0   \n",
      "2             0             0             0             1          1   \n",
      "3             0             0             1             0          0   \n",
      "4             0             0             0             1          1   \n",
      "\n",
      "   habitat_g  habitat_l  habitat_m  habitat_p  habitat_u  \n",
      "0          0          0          0          1          0  \n",
      "1          1          0          0          0          0  \n",
      "2          0          0          0          0          0  \n",
      "3          1          0          0          0          0  \n",
      "4          0          0          0          0          0  \n",
      "\n",
      "[5 rows x 99 columns]\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('mushroom_test.csv')\n",
    "print(df_test.head())\n",
    "test_label = np.array(df_test['class'])\n",
    "test_data =  np.array(df_test.drop('class', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5079, 98)   (5079,)\n",
      "(565, 98)   (565,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape, ' ', train_label.shape)\n",
    "print(test_data.shape, ' ', test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5079, 98)   (5079,)\n",
      "(565, 98)   (565,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = (train_data , train_label) , (test_data , test_label)\n",
    "x_train = x_train.reshape([x_train.shape[0], -1])\n",
    "x_test = x_test.reshape([x_test.shape[0], -1])\n",
    "print(x_train.shape, ' ', y_train.shape)\n",
    "print(x_test.shape, ' ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5079, 98)   (5079,)\n",
      "(565, 98)   (565,)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                6336      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 14,786\n",
      "Trainable params: 14,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## build model\n",
    "## write your code here\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = (train_data , train_label) , (test_data , test_label)\n",
    "x_train = x_train.reshape([x_train.shape[0], -1])\n",
    "x_test = x_test.reshape([x_test.shape[0], -1])\n",
    "print(x_train.shape, ' ', y_train.shape)\n",
    "print(x_test.shape, ' ', y_test.shape)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(98,)),\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.L1(0.01)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.L1(0.01)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(2, activation='softmax', kernel_regularizer=tf.keras.regularizers.L1(0.01))\n",
    "])\n",
    "\n",
    "\n",
    "#keras.optimizers.Adagrad(learning_rate=0.01)\n",
    "#keras.optimizers.Adam(learning_rate=0.01)\n",
    "#keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "\n",
    "# provide labels as one_hot representation => tf.keras.losses.CategoricalCrossentropy\n",
    "# provide labels as integers => tf.keras.losses.SparseCategoricalCrossentropy \n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "             loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "             metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "56/56 - 0s - loss: 7.5368 - accuracy: 0.8759 - val_loss: 5.4577 - val_accuracy: 0.9895\n",
      "Epoch 2/10\n",
      "56/56 - 0s - loss: 4.0241 - accuracy: 0.9826 - val_loss: 2.6606 - val_accuracy: 0.9961\n",
      "Epoch 3/10\n",
      "56/56 - 0s - loss: 1.7800 - accuracy: 0.9854 - val_loss: 0.9794 - val_accuracy: 0.9974\n",
      "Epoch 4/10\n",
      "56/56 - 0s - loss: 0.6412 - accuracy: 0.9899 - val_loss: 0.4005 - val_accuracy: 0.9974\n",
      "Epoch 5/10\n",
      "56/56 - 0s - loss: 0.3922 - accuracy: 0.9851 - val_loss: 0.3230 - val_accuracy: 0.9993\n",
      "Epoch 6/10\n",
      "56/56 - 0s - loss: 0.3398 - accuracy: 0.9904 - val_loss: 0.2892 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "56/56 - 0s - loss: 0.3144 - accuracy: 0.9882 - val_loss: 0.2663 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "56/56 - 0s - loss: 0.2941 - accuracy: 0.9885 - val_loss: 0.2481 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "56/56 - 0s - loss: 0.2781 - accuracy: 0.9924 - val_loss: 0.2348 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "56/56 - 0s - loss: 0.2605 - accuracy: 0.9916 - val_loss: 0.2230 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "## training \n",
    "## write your code here\n",
    "history = model.fit(x_train, y_train, batch_size=64, epochs=10, validation_split=0.3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model\n",
    "## write your code here\n",
    "model.save('DNN_mushroom.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 388us/step - loss: 0.2220 - accuracy: 1.0000\n",
      "[0.22203372418880463, 1.0]\n"
     ]
    }
   ],
   "source": [
    "## load model and use test data to evaluate result\n",
    "result = model.evaluate(x_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
