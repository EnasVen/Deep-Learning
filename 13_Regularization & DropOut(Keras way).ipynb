{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalty Restriction(Keras版本)\n",
    "透過L1 & L2 Regularization來防止類神經網路overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)   (60000,)\n",
      "(10000, 784)   (10000,)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 59,210\n",
      "Trainable params: 59,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "165/165 - 0s - loss: 14.0269 - accuracy: 0.6727 - val_loss: 9.2927 - val_accuracy: 0.8248\n",
      "Epoch 2/100\n",
      "165/165 - 0s - loss: 8.2833 - accuracy: 0.8570 - val_loss: 7.4561 - val_accuracy: 0.8716\n",
      "Epoch 3/100\n",
      "165/165 - 0s - loss: 6.7054 - accuracy: 0.8974 - val_loss: 6.1283 - val_accuracy: 0.8961\n",
      "Epoch 4/100\n",
      "165/165 - 0s - loss: 5.5347 - accuracy: 0.9182 - val_loss: 5.0942 - val_accuracy: 0.9123\n",
      "Epoch 5/100\n",
      "165/165 - 0s - loss: 4.6080 - accuracy: 0.9302 - val_loss: 4.2874 - val_accuracy: 0.9156\n",
      "Epoch 6/100\n",
      "165/165 - 0s - loss: 3.8619 - accuracy: 0.9379 - val_loss: 3.5902 - val_accuracy: 0.9262\n",
      "Epoch 7/100\n",
      "165/165 - 0s - loss: 3.2416 - accuracy: 0.9426 - val_loss: 3.0288 - val_accuracy: 0.9266\n",
      "Epoch 8/100\n",
      "165/165 - 0s - loss: 2.7171 - accuracy: 0.9479 - val_loss: 2.5404 - val_accuracy: 0.9323\n",
      "Epoch 9/100\n",
      "165/165 - 0s - loss: 2.2778 - accuracy: 0.9496 - val_loss: 2.1258 - val_accuracy: 0.9371\n",
      "Epoch 10/100\n",
      "165/165 - 0s - loss: 1.9184 - accuracy: 0.9510 - val_loss: 1.8106 - val_accuracy: 0.9351\n",
      "Epoch 11/100\n",
      "165/165 - 0s - loss: 1.6258 - accuracy: 0.9517 - val_loss: 1.5502 - val_accuracy: 0.9336\n",
      "Epoch 12/100\n",
      "165/165 - 0s - loss: 1.3810 - accuracy: 0.9522 - val_loss: 1.3167 - val_accuracy: 0.9359\n",
      "Epoch 13/100\n",
      "165/165 - 0s - loss: 1.1816 - accuracy: 0.9527 - val_loss: 1.1248 - val_accuracy: 0.9426\n",
      "Epoch 14/100\n",
      "165/165 - 0s - loss: 1.0192 - accuracy: 0.9544 - val_loss: 1.0239 - val_accuracy: 0.9318\n",
      "Epoch 15/100\n",
      "165/165 - 0s - loss: 0.9073 - accuracy: 0.9533 - val_loss: 0.8726 - val_accuracy: 0.9425\n",
      "Epoch 16/100\n",
      "165/165 - 0s - loss: 0.7872 - accuracy: 0.9576 - val_loss: 0.7730 - val_accuracy: 0.9464\n",
      "Epoch 17/100\n",
      "165/165 - 0s - loss: 0.6999 - accuracy: 0.9580 - val_loss: 0.7092 - val_accuracy: 0.9444\n",
      "Epoch 18/100\n",
      "165/165 - 0s - loss: 0.6341 - accuracy: 0.9580 - val_loss: 0.6287 - val_accuracy: 0.9483\n",
      "Epoch 19/100\n",
      "165/165 - 0s - loss: 0.5686 - accuracy: 0.9605 - val_loss: 0.5800 - val_accuracy: 0.9479\n",
      "Epoch 20/100\n",
      "165/165 - 0s - loss: 0.5213 - accuracy: 0.9617 - val_loss: 0.5412 - val_accuracy: 0.9482\n",
      "Epoch 21/100\n",
      "165/165 - 0s - loss: 0.4830 - accuracy: 0.9613 - val_loss: 0.5030 - val_accuracy: 0.9494\n",
      "Epoch 22/100\n",
      "165/165 - 0s - loss: 0.4500 - accuracy: 0.9637 - val_loss: 0.4715 - val_accuracy: 0.9529\n",
      "Epoch 23/100\n",
      "165/165 - 0s - loss: 0.4255 - accuracy: 0.9649 - val_loss: 0.4730 - val_accuracy: 0.9458\n",
      "Epoch 24/100\n",
      "165/165 - 0s - loss: 0.4057 - accuracy: 0.9643 - val_loss: 0.4348 - val_accuracy: 0.9536\n",
      "Epoch 25/100\n",
      "165/165 - 0s - loss: 0.3853 - accuracy: 0.9671 - val_loss: 0.4156 - val_accuracy: 0.9547\n",
      "Epoch 26/100\n",
      "165/165 - 0s - loss: 0.3673 - accuracy: 0.9689 - val_loss: 0.3971 - val_accuracy: 0.9561\n",
      "Epoch 27/100\n",
      "165/165 - 0s - loss: 0.3544 - accuracy: 0.9690 - val_loss: 0.3937 - val_accuracy: 0.9535\n",
      "Epoch 28/100\n",
      "165/165 - 0s - loss: 0.3443 - accuracy: 0.9693 - val_loss: 0.4022 - val_accuracy: 0.9481\n",
      "Epoch 29/100\n",
      "165/165 - 0s - loss: 0.3315 - accuracy: 0.9700 - val_loss: 0.3702 - val_accuracy: 0.9572\n",
      "Epoch 30/100\n",
      "165/165 - 0s - loss: 0.3264 - accuracy: 0.9695 - val_loss: 0.3673 - val_accuracy: 0.9552\n",
      "Epoch 31/100\n",
      "165/165 - 0s - loss: 0.3090 - accuracy: 0.9722 - val_loss: 0.3620 - val_accuracy: 0.9539\n",
      "Epoch 32/100\n",
      "165/165 - 0s - loss: 0.3048 - accuracy: 0.9714 - val_loss: 0.3555 - val_accuracy: 0.9548\n",
      "Epoch 33/100\n",
      "165/165 - 0s - loss: 0.2948 - accuracy: 0.9725 - val_loss: 0.3404 - val_accuracy: 0.9571\n",
      "Epoch 34/100\n",
      "165/165 - 0s - loss: 0.2881 - accuracy: 0.9731 - val_loss: 0.3368 - val_accuracy: 0.9579\n",
      "Epoch 35/100\n",
      "165/165 - 0s - loss: 0.2823 - accuracy: 0.9743 - val_loss: 0.3459 - val_accuracy: 0.9546\n",
      "Epoch 36/100\n",
      "165/165 - 0s - loss: 0.2795 - accuracy: 0.9741 - val_loss: 0.3276 - val_accuracy: 0.9582\n",
      "Epoch 37/100\n",
      "165/165 - 0s - loss: 0.2706 - accuracy: 0.9752 - val_loss: 0.3433 - val_accuracy: 0.9529\n",
      "Epoch 38/100\n",
      "165/165 - 0s - loss: 0.2683 - accuracy: 0.9758 - val_loss: 0.3297 - val_accuracy: 0.9558\n",
      "Epoch 39/100\n",
      "165/165 - 0s - loss: 0.2610 - accuracy: 0.9765 - val_loss: 0.3262 - val_accuracy: 0.9564\n",
      "Epoch 40/100\n",
      "165/165 - 0s - loss: 0.2592 - accuracy: 0.9757 - val_loss: 0.3175 - val_accuracy: 0.9582\n",
      "Epoch 41/100\n",
      "165/165 - 0s - loss: 0.2515 - accuracy: 0.9779 - val_loss: 0.3138 - val_accuracy: 0.9584\n",
      "Epoch 42/100\n",
      "165/165 - 0s - loss: 0.2464 - accuracy: 0.9786 - val_loss: 0.3049 - val_accuracy: 0.9600\n",
      "Epoch 43/100\n",
      "165/165 - 0s - loss: 0.2434 - accuracy: 0.9786 - val_loss: 0.3039 - val_accuracy: 0.9607\n",
      "Epoch 44/100\n",
      "165/165 - 0s - loss: 0.2451 - accuracy: 0.9772 - val_loss: 0.3069 - val_accuracy: 0.9584\n",
      "Epoch 45/100\n",
      "165/165 - 0s - loss: 0.2352 - accuracy: 0.9789 - val_loss: 0.3016 - val_accuracy: 0.9591\n",
      "Epoch 46/100\n",
      "165/165 - 0s - loss: 0.2343 - accuracy: 0.9796 - val_loss: 0.2989 - val_accuracy: 0.9588\n",
      "Epoch 47/100\n",
      "165/165 - 0s - loss: 0.2304 - accuracy: 0.9790 - val_loss: 0.3013 - val_accuracy: 0.9590\n",
      "Epoch 48/100\n",
      "165/165 - 0s - loss: 0.2249 - accuracy: 0.9810 - val_loss: 0.3003 - val_accuracy: 0.9593\n",
      "Epoch 49/100\n",
      "165/165 - 0s - loss: 0.2242 - accuracy: 0.9801 - val_loss: 0.3054 - val_accuracy: 0.9564\n",
      "Epoch 50/100\n",
      "165/165 - 0s - loss: 0.2209 - accuracy: 0.9815 - val_loss: 0.2959 - val_accuracy: 0.9594\n",
      "Epoch 51/100\n",
      "165/165 - 0s - loss: 0.2199 - accuracy: 0.9805 - val_loss: 0.3020 - val_accuracy: 0.9556\n",
      "Epoch 52/100\n",
      "165/165 - 0s - loss: 0.2189 - accuracy: 0.9814 - val_loss: 0.2970 - val_accuracy: 0.9590\n",
      "Epoch 53/100\n",
      "165/165 - 0s - loss: 0.2147 - accuracy: 0.9818 - val_loss: 0.2912 - val_accuracy: 0.9602\n",
      "Epoch 54/100\n",
      "165/165 - 0s - loss: 0.2143 - accuracy: 0.9814 - val_loss: 0.2950 - val_accuracy: 0.9592\n",
      "Epoch 55/100\n",
      "165/165 - 0s - loss: 0.2134 - accuracy: 0.9815 - val_loss: 0.2989 - val_accuracy: 0.9569\n",
      "Epoch 56/100\n",
      "165/165 - 0s - loss: 0.2100 - accuracy: 0.9828 - val_loss: 0.2933 - val_accuracy: 0.9577\n",
      "Epoch 57/100\n",
      "165/165 - 0s - loss: 0.2103 - accuracy: 0.9820 - val_loss: 0.2879 - val_accuracy: 0.9609\n",
      "Epoch 58/100\n",
      "165/165 - 0s - loss: 0.2041 - accuracy: 0.9836 - val_loss: 0.2869 - val_accuracy: 0.9607\n",
      "Epoch 59/100\n",
      "165/165 - 0s - loss: 0.2006 - accuracy: 0.9851 - val_loss: 0.2856 - val_accuracy: 0.9597\n",
      "Epoch 60/100\n",
      "165/165 - 0s - loss: 0.2009 - accuracy: 0.9847 - val_loss: 0.2949 - val_accuracy: 0.9579\n",
      "Epoch 61/100\n",
      "165/165 - 0s - loss: 0.2017 - accuracy: 0.9841 - val_loss: 0.2887 - val_accuracy: 0.9595\n",
      "Epoch 62/100\n",
      "165/165 - 0s - loss: 0.2027 - accuracy: 0.9834 - val_loss: 0.3202 - val_accuracy: 0.9489\n",
      "Epoch 63/100\n",
      "165/165 - 0s - loss: 0.2021 - accuracy: 0.9838 - val_loss: 0.2874 - val_accuracy: 0.9591\n",
      "Epoch 64/100\n",
      "165/165 - 0s - loss: 0.1956 - accuracy: 0.9860 - val_loss: 0.2835 - val_accuracy: 0.9590\n",
      "Epoch 65/100\n",
      "165/165 - 0s - loss: 0.1931 - accuracy: 0.9863 - val_loss: 0.2875 - val_accuracy: 0.9589\n",
      "Epoch 66/100\n",
      "165/165 - 0s - loss: 0.1944 - accuracy: 0.9850 - val_loss: 0.2948 - val_accuracy: 0.9569\n",
      "Epoch 67/100\n",
      "165/165 - 0s - loss: 0.1978 - accuracy: 0.9846 - val_loss: 0.2883 - val_accuracy: 0.9583\n",
      "Epoch 68/100\n",
      "165/165 - 0s - loss: 0.1922 - accuracy: 0.9859 - val_loss: 0.2944 - val_accuracy: 0.9558\n",
      "Epoch 69/100\n",
      "165/165 - 0s - loss: 0.1906 - accuracy: 0.9861 - val_loss: 0.2840 - val_accuracy: 0.9602\n",
      "Epoch 70/100\n",
      "165/165 - 0s - loss: 0.1870 - accuracy: 0.9865 - val_loss: 0.2906 - val_accuracy: 0.9574\n",
      "Epoch 71/100\n",
      "165/165 - 0s - loss: 0.1850 - accuracy: 0.9880 - val_loss: 0.2816 - val_accuracy: 0.9600\n",
      "Epoch 72/100\n",
      "165/165 - 0s - loss: 0.1836 - accuracy: 0.9871 - val_loss: 0.2949 - val_accuracy: 0.9556\n",
      "Epoch 73/100\n",
      "165/165 - 0s - loss: 0.1859 - accuracy: 0.9865 - val_loss: 0.3021 - val_accuracy: 0.9544\n",
      "Epoch 74/100\n",
      "165/165 - 0s - loss: 0.1816 - accuracy: 0.9881 - val_loss: 0.2862 - val_accuracy: 0.9585\n",
      "Epoch 75/100\n",
      "165/165 - 0s - loss: 0.1919 - accuracy: 0.9844 - val_loss: 0.2864 - val_accuracy: 0.9578\n",
      "Epoch 76/100\n",
      "165/165 - 0s - loss: 0.1824 - accuracy: 0.9880 - val_loss: 0.2848 - val_accuracy: 0.9599\n",
      "Epoch 77/100\n",
      "165/165 - 0s - loss: 0.1783 - accuracy: 0.9889 - val_loss: 0.2904 - val_accuracy: 0.9554\n",
      "Epoch 78/100\n",
      "165/165 - 0s - loss: 0.1797 - accuracy: 0.9879 - val_loss: 0.2831 - val_accuracy: 0.9603\n",
      "Epoch 79/100\n",
      "165/165 - 0s - loss: 0.1785 - accuracy: 0.9875 - val_loss: 0.2876 - val_accuracy: 0.9570\n",
      "Epoch 80/100\n",
      "165/165 - 0s - loss: 0.1746 - accuracy: 0.9893 - val_loss: 0.2802 - val_accuracy: 0.9603\n",
      "Epoch 81/100\n",
      "165/165 - 0s - loss: 0.1740 - accuracy: 0.9891 - val_loss: 0.2881 - val_accuracy: 0.9587\n",
      "Epoch 82/100\n",
      "165/165 - 0s - loss: 0.1732 - accuracy: 0.9887 - val_loss: 0.2888 - val_accuracy: 0.9583\n",
      "Epoch 83/100\n",
      "165/165 - 0s - loss: 0.1729 - accuracy: 0.9894 - val_loss: 0.2861 - val_accuracy: 0.9581\n",
      "Epoch 84/100\n",
      "165/165 - 0s - loss: 0.1699 - accuracy: 0.9903 - val_loss: 0.2810 - val_accuracy: 0.9589\n",
      "Epoch 85/100\n",
      "165/165 - 0s - loss: 0.1726 - accuracy: 0.9893 - val_loss: 0.2836 - val_accuracy: 0.9587\n",
      "Epoch 86/100\n",
      "165/165 - 0s - loss: 0.1716 - accuracy: 0.9893 - val_loss: 0.2877 - val_accuracy: 0.9572\n",
      "Epoch 87/100\n",
      "165/165 - 0s - loss: 0.1724 - accuracy: 0.9889 - val_loss: 0.2860 - val_accuracy: 0.9578\n",
      "Epoch 88/100\n",
      "165/165 - 0s - loss: 0.1680 - accuracy: 0.9908 - val_loss: 0.2811 - val_accuracy: 0.9591\n",
      "Epoch 89/100\n",
      "165/165 - 0s - loss: 0.1679 - accuracy: 0.9899 - val_loss: 0.3070 - val_accuracy: 0.9513\n",
      "Epoch 90/100\n",
      "165/165 - 0s - loss: 0.1715 - accuracy: 0.9886 - val_loss: 0.2828 - val_accuracy: 0.9591\n",
      "Epoch 91/100\n",
      "165/165 - 0s - loss: 0.1661 - accuracy: 0.9904 - val_loss: 0.2828 - val_accuracy: 0.9572\n",
      "Epoch 92/100\n",
      "165/165 - 0s - loss: 0.1678 - accuracy: 0.9899 - val_loss: 0.2820 - val_accuracy: 0.9593\n",
      "Epoch 93/100\n",
      "165/165 - 0s - loss: 0.1649 - accuracy: 0.9910 - val_loss: 0.2810 - val_accuracy: 0.9583\n",
      "Epoch 94/100\n",
      "165/165 - 0s - loss: 0.1633 - accuracy: 0.9911 - val_loss: 0.2787 - val_accuracy: 0.9595\n",
      "Epoch 95/100\n",
      "165/165 - 0s - loss: 0.1646 - accuracy: 0.9904 - val_loss: 0.2902 - val_accuracy: 0.9572\n",
      "Epoch 96/100\n",
      "165/165 - 0s - loss: 0.1648 - accuracy: 0.9905 - val_loss: 0.2912 - val_accuracy: 0.9564\n",
      "Epoch 97/100\n",
      "165/165 - 0s - loss: 0.1643 - accuracy: 0.9899 - val_loss: 0.2949 - val_accuracy: 0.9557\n",
      "Epoch 98/100\n",
      "165/165 - 0s - loss: 0.1652 - accuracy: 0.9895 - val_loss: 0.2885 - val_accuracy: 0.9578\n",
      "Epoch 99/100\n",
      "165/165 - 0s - loss: 0.1595 - accuracy: 0.9920 - val_loss: 0.2776 - val_accuracy: 0.9591\n",
      "Epoch 100/100\n",
      "165/165 - 0s - loss: 0.1609 - accuracy: 0.9911 - val_loss: 0.2841 - val_accuracy: 0.9580\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape([x_train.shape[0], -1])\n",
    "x_test = x_test.reshape([x_test.shape[0], -1])\n",
    "print(x_train.shape, ' ', y_train.shape)\n",
    "print(x_test.shape, ' ', y_test.shape)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(784,)),\n",
    "#     layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.L1L2(0.01 , 0.02)),\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.L1(0.01)),\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.L1(0.01)),\n",
    "    layers.Dense(10, activation='softmax', kernel_regularizer=tf.keras.regularizers.L1(0.01))\n",
    "])\n",
    "\n",
    "\n",
    "#keras.optimizers.Adagrad(learning_rate=0.01)\n",
    "#keras.optimizers.Adam(learning_rate=0.01)\n",
    "#keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "\n",
    "# provide labels as one_hot representation => tf.keras.losses.CategoricalCrossentropy\n",
    "# provide labels as integers => tf.keras.losses.SparseCategoricalCrossentropy \n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "             loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "             metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100, validation_split=0.3, verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout(Keras版本)\n",
    "類似負重訓練的效果，在training時將部分neuron移除，test時再補回來!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)   (60000,)\n",
      "(10000, 784)   (10000,)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 59,210\n",
      "Trainable params: 59,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "165/165 - 0s - loss: 14.1817 - accuracy: 0.3163 - val_loss: 9.7888 - val_accuracy: 0.4633\n",
      "Epoch 2/100\n",
      "165/165 - 0s - loss: 8.7625 - accuracy: 0.5245 - val_loss: 7.5016 - val_accuracy: 0.6594\n",
      "Epoch 3/100\n",
      "165/165 - 0s - loss: 6.6568 - accuracy: 0.6931 - val_loss: 5.6912 - val_accuracy: 0.8068\n",
      "Epoch 4/100\n",
      "165/165 - 0s - loss: 5.0692 - accuracy: 0.8050 - val_loss: 4.3518 - val_accuracy: 0.8623\n",
      "Epoch 5/100\n",
      "165/165 - 0s - loss: 3.8899 - accuracy: 0.8499 - val_loss: 3.3255 - val_accuracy: 0.8871\n",
      "Epoch 6/100\n",
      "165/165 - 0s - loss: 3.0141 - accuracy: 0.8778 - val_loss: 2.6012 - val_accuracy: 0.8973\n",
      "Epoch 7/100\n",
      "165/165 - 0s - loss: 2.3885 - accuracy: 0.8901 - val_loss: 2.0736 - val_accuracy: 0.9047\n",
      "Epoch 8/100\n",
      "165/165 - 0s - loss: 1.9300 - accuracy: 0.8965 - val_loss: 1.6778 - val_accuracy: 0.9108\n",
      "Epoch 9/100\n",
      "165/165 - 0s - loss: 1.5942 - accuracy: 0.8996 - val_loss: 1.3969 - val_accuracy: 0.9160\n",
      "Epoch 10/100\n",
      "165/165 - 0s - loss: 1.3507 - accuracy: 0.9006 - val_loss: 1.1873 - val_accuracy: 0.9177\n",
      "Epoch 11/100\n",
      "165/165 - 0s - loss: 1.1610 - accuracy: 0.9067 - val_loss: 1.0232 - val_accuracy: 0.9194\n",
      "Epoch 12/100\n",
      "165/165 - 0s - loss: 1.0261 - accuracy: 0.9053 - val_loss: 0.9001 - val_accuracy: 0.9224\n",
      "Epoch 13/100\n",
      "165/165 - 1s - loss: 0.9265 - accuracy: 0.9076 - val_loss: 0.8203 - val_accuracy: 0.9229\n",
      "Epoch 14/100\n",
      "165/165 - 0s - loss: 0.8451 - accuracy: 0.9106 - val_loss: 0.7562 - val_accuracy: 0.9226\n",
      "Epoch 15/100\n",
      "165/165 - 0s - loss: 0.7921 - accuracy: 0.9109 - val_loss: 0.7041 - val_accuracy: 0.9251\n",
      "Epoch 16/100\n",
      "165/165 - 0s - loss: 0.7452 - accuracy: 0.9116 - val_loss: 0.6655 - val_accuracy: 0.9271\n",
      "Epoch 17/100\n",
      "165/165 - 0s - loss: 0.7087 - accuracy: 0.9122 - val_loss: 0.6463 - val_accuracy: 0.9230\n",
      "Epoch 18/100\n",
      "165/165 - 0s - loss: 0.6897 - accuracy: 0.9131 - val_loss: 0.6134 - val_accuracy: 0.9278\n",
      "Epoch 19/100\n",
      "165/165 - 0s - loss: 0.6669 - accuracy: 0.9141 - val_loss: 0.6054 - val_accuracy: 0.9262\n",
      "Epoch 20/100\n",
      "165/165 - 0s - loss: 0.6586 - accuracy: 0.9139 - val_loss: 0.5865 - val_accuracy: 0.9278\n",
      "Epoch 21/100\n",
      "165/165 - 0s - loss: 0.6358 - accuracy: 0.9161 - val_loss: 0.5725 - val_accuracy: 0.9277\n",
      "Epoch 22/100\n",
      "165/165 - 0s - loss: 0.6308 - accuracy: 0.9152 - val_loss: 0.5648 - val_accuracy: 0.9284\n",
      "Epoch 23/100\n",
      "165/165 - 0s - loss: 0.6157 - accuracy: 0.9175 - val_loss: 0.5606 - val_accuracy: 0.9270\n",
      "Epoch 24/100\n",
      "165/165 - 0s - loss: 0.6105 - accuracy: 0.9155 - val_loss: 0.5491 - val_accuracy: 0.9287\n",
      "Epoch 25/100\n",
      "165/165 - 0s - loss: 0.5979 - accuracy: 0.9168 - val_loss: 0.5461 - val_accuracy: 0.9298\n",
      "Epoch 26/100\n",
      "165/165 - 0s - loss: 0.5948 - accuracy: 0.9171 - val_loss: 0.5411 - val_accuracy: 0.9294\n",
      "Epoch 27/100\n",
      "165/165 - 0s - loss: 0.5897 - accuracy: 0.9173 - val_loss: 0.5352 - val_accuracy: 0.9313\n",
      "Epoch 28/100\n",
      "165/165 - 0s - loss: 0.5829 - accuracy: 0.9187 - val_loss: 0.5293 - val_accuracy: 0.9303\n",
      "Epoch 29/100\n",
      "165/165 - 0s - loss: 0.5759 - accuracy: 0.9200 - val_loss: 0.5245 - val_accuracy: 0.9292\n",
      "Epoch 30/100\n",
      "165/165 - 0s - loss: 0.5671 - accuracy: 0.9209 - val_loss: 0.5227 - val_accuracy: 0.9298\n",
      "Epoch 31/100\n",
      "165/165 - 0s - loss: 0.5645 - accuracy: 0.9213 - val_loss: 0.5199 - val_accuracy: 0.9303\n",
      "Epoch 32/100\n",
      "165/165 - 0s - loss: 0.5645 - accuracy: 0.9203 - val_loss: 0.5171 - val_accuracy: 0.9290\n",
      "Epoch 33/100\n",
      "165/165 - 0s - loss: 0.5604 - accuracy: 0.9198 - val_loss: 0.5185 - val_accuracy: 0.9292\n",
      "Epoch 34/100\n",
      "165/165 - 0s - loss: 0.5582 - accuracy: 0.9210 - val_loss: 0.5112 - val_accuracy: 0.9312\n",
      "Epoch 35/100\n",
      "165/165 - 0s - loss: 0.5570 - accuracy: 0.9205 - val_loss: 0.5140 - val_accuracy: 0.9309\n",
      "Epoch 36/100\n",
      "165/165 - 0s - loss: 0.5487 - accuracy: 0.9221 - val_loss: 0.5092 - val_accuracy: 0.9297\n",
      "Epoch 37/100\n",
      "165/165 - 0s - loss: 0.5438 - accuracy: 0.9223 - val_loss: 0.5055 - val_accuracy: 0.9309\n",
      "Epoch 38/100\n",
      "165/165 - 0s - loss: 0.5444 - accuracy: 0.9219 - val_loss: 0.5001 - val_accuracy: 0.9326\n",
      "Epoch 39/100\n",
      "165/165 - 0s - loss: 0.5390 - accuracy: 0.9240 - val_loss: 0.4971 - val_accuracy: 0.9332\n",
      "Epoch 40/100\n",
      "165/165 - 0s - loss: 0.5379 - accuracy: 0.9242 - val_loss: 0.4976 - val_accuracy: 0.9321\n",
      "Epoch 41/100\n",
      "165/165 - 0s - loss: 0.5374 - accuracy: 0.9237 - val_loss: 0.4995 - val_accuracy: 0.9306\n",
      "Epoch 42/100\n",
      "165/165 - 0s - loss: 0.5348 - accuracy: 0.9245 - val_loss: 0.4930 - val_accuracy: 0.9322\n",
      "Epoch 43/100\n",
      "165/165 - 0s - loss: 0.5343 - accuracy: 0.9242 - val_loss: 0.4905 - val_accuracy: 0.9332\n",
      "Epoch 44/100\n",
      "165/165 - 1s - loss: 0.5264 - accuracy: 0.9253 - val_loss: 0.4931 - val_accuracy: 0.9322\n",
      "Epoch 45/100\n",
      "165/165 - 0s - loss: 0.5281 - accuracy: 0.9244 - val_loss: 0.4850 - val_accuracy: 0.9335\n",
      "Epoch 46/100\n",
      "165/165 - 0s - loss: 0.5234 - accuracy: 0.9256 - val_loss: 0.4875 - val_accuracy: 0.9323\n",
      "Epoch 47/100\n",
      "165/165 - 1s - loss: 0.5276 - accuracy: 0.9245 - val_loss: 0.4881 - val_accuracy: 0.9334\n",
      "Epoch 48/100\n",
      "165/165 - 0s - loss: 0.5199 - accuracy: 0.9250 - val_loss: 0.4839 - val_accuracy: 0.9316\n",
      "Epoch 49/100\n",
      "165/165 - 0s - loss: 0.5149 - accuracy: 0.9263 - val_loss: 0.4797 - val_accuracy: 0.9343\n",
      "Epoch 50/100\n",
      "165/165 - 1s - loss: 0.5153 - accuracy: 0.9250 - val_loss: 0.4886 - val_accuracy: 0.9321\n",
      "Epoch 51/100\n",
      "165/165 - 0s - loss: 0.5123 - accuracy: 0.9273 - val_loss: 0.4800 - val_accuracy: 0.9329\n",
      "Epoch 52/100\n",
      "165/165 - 0s - loss: 0.5116 - accuracy: 0.9266 - val_loss: 0.4745 - val_accuracy: 0.9337\n",
      "Epoch 53/100\n",
      "165/165 - 0s - loss: 0.5094 - accuracy: 0.9259 - val_loss: 0.4779 - val_accuracy: 0.9329\n",
      "Epoch 54/100\n",
      "165/165 - 0s - loss: 0.5077 - accuracy: 0.9267 - val_loss: 0.4780 - val_accuracy: 0.9316\n",
      "Epoch 55/100\n",
      "165/165 - 0s - loss: 0.5067 - accuracy: 0.9287 - val_loss: 0.4776 - val_accuracy: 0.9331\n",
      "Epoch 56/100\n",
      "165/165 - 0s - loss: 0.5035 - accuracy: 0.9278 - val_loss: 0.4728 - val_accuracy: 0.9337\n",
      "Epoch 57/100\n",
      "165/165 - 1s - loss: 0.5076 - accuracy: 0.9266 - val_loss: 0.4782 - val_accuracy: 0.9333\n",
      "Epoch 58/100\n",
      "165/165 - 0s - loss: 0.5035 - accuracy: 0.9289 - val_loss: 0.4702 - val_accuracy: 0.9336\n",
      "Epoch 59/100\n",
      "165/165 - 0s - loss: 0.4998 - accuracy: 0.9287 - val_loss: 0.4792 - val_accuracy: 0.9318\n",
      "Epoch 60/100\n",
      "165/165 - 0s - loss: 0.4975 - accuracy: 0.9294 - val_loss: 0.4742 - val_accuracy: 0.9326\n",
      "Epoch 61/100\n",
      "165/165 - 0s - loss: 0.5011 - accuracy: 0.9300 - val_loss: 0.4796 - val_accuracy: 0.9316\n",
      "Epoch 62/100\n",
      "165/165 - 0s - loss: 0.4969 - accuracy: 0.9286 - val_loss: 0.4752 - val_accuracy: 0.9314\n",
      "Epoch 63/100\n",
      "165/165 - 0s - loss: 0.4939 - accuracy: 0.9288 - val_loss: 0.4718 - val_accuracy: 0.9326\n",
      "Epoch 64/100\n",
      "165/165 - 0s - loss: 0.4955 - accuracy: 0.9271 - val_loss: 0.4777 - val_accuracy: 0.9327\n",
      "Epoch 65/100\n",
      "165/165 - 0s - loss: 0.4984 - accuracy: 0.9280 - val_loss: 0.4702 - val_accuracy: 0.9345\n",
      "Epoch 66/100\n",
      "165/165 - 0s - loss: 0.4913 - accuracy: 0.9291 - val_loss: 0.4693 - val_accuracy: 0.9334\n",
      "Epoch 67/100\n",
      "165/165 - 0s - loss: 0.4889 - accuracy: 0.9300 - val_loss: 0.4777 - val_accuracy: 0.9301\n",
      "Epoch 68/100\n",
      "165/165 - 0s - loss: 0.4939 - accuracy: 0.9278 - val_loss: 0.4670 - val_accuracy: 0.9341\n",
      "Epoch 69/100\n",
      "165/165 - 0s - loss: 0.4850 - accuracy: 0.9293 - val_loss: 0.4667 - val_accuracy: 0.9334\n",
      "Epoch 70/100\n",
      "165/165 - 0s - loss: 0.4867 - accuracy: 0.9314 - val_loss: 0.4743 - val_accuracy: 0.9331\n",
      "Epoch 71/100\n",
      "165/165 - 0s - loss: 0.4890 - accuracy: 0.9289 - val_loss: 0.4623 - val_accuracy: 0.9336\n",
      "Epoch 72/100\n",
      "165/165 - 1s - loss: 0.4828 - accuracy: 0.9304 - val_loss: 0.4732 - val_accuracy: 0.9339\n",
      "Epoch 73/100\n",
      "165/165 - 0s - loss: 0.4846 - accuracy: 0.9300 - val_loss: 0.4667 - val_accuracy: 0.9334\n",
      "Epoch 74/100\n",
      "165/165 - 0s - loss: 0.4848 - accuracy: 0.9302 - val_loss: 0.4707 - val_accuracy: 0.9324\n",
      "Epoch 75/100\n",
      "165/165 - 0s - loss: 0.4783 - accuracy: 0.9306 - val_loss: 0.4600 - val_accuracy: 0.9340\n",
      "Epoch 76/100\n",
      "165/165 - 0s - loss: 0.4789 - accuracy: 0.9309 - val_loss: 0.4571 - val_accuracy: 0.9346\n",
      "Epoch 77/100\n",
      "165/165 - 0s - loss: 0.4783 - accuracy: 0.9298 - val_loss: 0.4627 - val_accuracy: 0.9338\n",
      "Epoch 78/100\n",
      "165/165 - 0s - loss: 0.4753 - accuracy: 0.9305 - val_loss: 0.4604 - val_accuracy: 0.9335\n",
      "Epoch 79/100\n",
      "165/165 - 0s - loss: 0.4816 - accuracy: 0.9292 - val_loss: 0.4573 - val_accuracy: 0.9334\n",
      "Epoch 80/100\n",
      "165/165 - 0s - loss: 0.4746 - accuracy: 0.9320 - val_loss: 0.4720 - val_accuracy: 0.9319\n",
      "Epoch 81/100\n",
      "165/165 - 0s - loss: 0.4755 - accuracy: 0.9318 - val_loss: 0.4676 - val_accuracy: 0.9329\n",
      "Epoch 82/100\n",
      "165/165 - 0s - loss: 0.4739 - accuracy: 0.9315 - val_loss: 0.4653 - val_accuracy: 0.9318\n",
      "Epoch 83/100\n",
      "165/165 - 0s - loss: 0.4750 - accuracy: 0.9308 - val_loss: 0.4587 - val_accuracy: 0.9337\n",
      "Epoch 84/100\n",
      "165/165 - 0s - loss: 0.4709 - accuracy: 0.9312 - val_loss: 0.4622 - val_accuracy: 0.9342\n",
      "Epoch 85/100\n",
      "165/165 - 0s - loss: 0.4746 - accuracy: 0.9322 - val_loss: 0.4605 - val_accuracy: 0.9322\n",
      "Epoch 86/100\n",
      "165/165 - 0s - loss: 0.4698 - accuracy: 0.9324 - val_loss: 0.4633 - val_accuracy: 0.9346\n",
      "Epoch 87/100\n",
      "165/165 - 0s - loss: 0.4698 - accuracy: 0.9318 - val_loss: 0.4550 - val_accuracy: 0.9338\n",
      "Epoch 88/100\n",
      "165/165 - 0s - loss: 0.4642 - accuracy: 0.9352 - val_loss: 0.4486 - val_accuracy: 0.9373\n",
      "Epoch 89/100\n",
      "165/165 - 0s - loss: 0.4582 - accuracy: 0.9360 - val_loss: 0.4470 - val_accuracy: 0.9382\n",
      "Epoch 90/100\n",
      "165/165 - 0s - loss: 0.4615 - accuracy: 0.9343 - val_loss: 0.4427 - val_accuracy: 0.9377\n",
      "Epoch 91/100\n",
      "165/165 - 0s - loss: 0.4569 - accuracy: 0.9354 - val_loss: 0.4481 - val_accuracy: 0.9366\n",
      "Epoch 92/100\n",
      "165/165 - 0s - loss: 0.4549 - accuracy: 0.9365 - val_loss: 0.4426 - val_accuracy: 0.9384\n",
      "Epoch 93/100\n",
      "165/165 - 0s - loss: 0.4567 - accuracy: 0.9356 - val_loss: 0.4424 - val_accuracy: 0.9369\n",
      "Epoch 94/100\n",
      "165/165 - 0s - loss: 0.4518 - accuracy: 0.9362 - val_loss: 0.4480 - val_accuracy: 0.9379\n",
      "Epoch 95/100\n",
      "165/165 - 0s - loss: 0.4573 - accuracy: 0.9364 - val_loss: 0.4424 - val_accuracy: 0.9392\n",
      "Epoch 96/100\n",
      "165/165 - 0s - loss: 0.4529 - accuracy: 0.9360 - val_loss: 0.4448 - val_accuracy: 0.9369\n",
      "Epoch 97/100\n",
      "165/165 - 0s - loss: 0.4499 - accuracy: 0.9362 - val_loss: 0.4388 - val_accuracy: 0.9394\n",
      "Epoch 98/100\n",
      "165/165 - 0s - loss: 0.4468 - accuracy: 0.9372 - val_loss: 0.4426 - val_accuracy: 0.9377\n",
      "Epoch 99/100\n",
      "165/165 - 0s - loss: 0.4513 - accuracy: 0.9356 - val_loss: 0.4489 - val_accuracy: 0.9382\n",
      "Epoch 100/100\n",
      "165/165 - 0s - loss: 0.4455 - accuracy: 0.9381 - val_loss: 0.4421 - val_accuracy: 0.9362\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape([x_train.shape[0], -1])\n",
    "x_test = x_test.reshape([x_test.shape[0], -1])\n",
    "print(x_train.shape, ' ', y_train.shape)\n",
    "print(x_test.shape, ' ', y_test.shape)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(784,)),\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.L1(0.01)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.L1(0.01)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(10, activation='softmax', kernel_regularizer=tf.keras.regularizers.L1(0.01))\n",
    "])\n",
    "\n",
    "\n",
    "#keras.optimizers.Adagrad(learning_rate=0.01)\n",
    "#keras.optimizers.Adam(learning_rate=0.01)\n",
    "#keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "\n",
    "# provide labels as one_hot representation => tf.keras.losses.CategoricalCrossentropy\n",
    "# provide labels as integers => tf.keras.losses.SparseCategoricalCrossentropy \n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "             loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "             metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100, validation_split=0.3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend(['training', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 601us/step - loss: 0.4262 - accuracy: 0.9404\n",
      "[0.42615756392478943, 0.9404000043869019]\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(x_test, y_test)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
