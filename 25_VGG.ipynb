{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DY9VFTFpusg-"
   },
   "source": [
    "# VGG13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "icIzgO1rusg-",
    "outputId": "03e187b9-c75b-4f4a-d4fc-36d8c41ad58d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000,) (10000, 32, 32, 3) (10000,)\n",
      "sample: (128, 32, 32, 3) (128,) tf.Tensor(-1.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "=================================================================\n",
      "Total params: 9,404,992\n",
      "Trainable params: 9,404,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 165,514\n",
      "Trainable params: 165,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0 0 loss: 2.302992582321167\n",
      "0 100 loss: 1.9034745693206787\n",
      "0 200 loss: 1.7845792770385742\n",
      "0 300 loss: 1.789175033569336\n",
      "0 acc: 0.4393\n",
      "1 0 loss: 1.4939123392105103\n",
      "1 100 loss: 1.4455008506774902\n",
      "1 200 loss: 1.3084189891815186\n",
      "1 300 loss: 1.2056293487548828\n",
      "1 acc: 0.5521\n",
      "2 0 loss: 1.2147811651229858\n",
      "2 100 loss: 1.0474493503570557\n",
      "2 200 loss: 1.301928162574768\n",
      "2 300 loss: 1.0534210205078125\n",
      "2 acc: 0.5666\n",
      "3 0 loss: 0.9677833914756775\n",
      "3 100 loss: 1.1415177583694458\n",
      "3 200 loss: 1.009701132774353\n",
      "3 300 loss: 0.8769439458847046\n",
      "3 acc: 0.6427\n",
      "4 0 loss: 0.9438665509223938\n",
      "4 100 loss: 0.8413580656051636\n",
      "4 200 loss: 0.872194766998291\n",
      "4 300 loss: 0.8956065773963928\n",
      "4 acc: 0.6827\n",
      "5 0 loss: 0.7751904726028442\n",
      "5 100 loss: 0.870276927947998\n",
      "5 200 loss: 0.7713571786880493\n",
      "5 300 loss: 0.7129082679748535\n",
      "5 acc: 0.7042\n",
      "6 0 loss: 0.7772819995880127\n",
      "6 100 loss: 0.743979811668396\n",
      "6 200 loss: 0.7251017689704895\n",
      "6 300 loss: 0.5792276263237\n",
      "6 acc: 0.7373\n",
      "7 0 loss: 0.43060415983200073\n",
      "7 100 loss: 0.5898911356925964\n",
      "7 200 loss: 0.5154841542243958\n",
      "7 300 loss: 0.5183607339859009\n",
      "7 acc: 0.7353\n",
      "8 0 loss: 0.47104811668395996\n",
      "8 100 loss: 0.47484710812568665\n",
      "8 200 loss: 0.48264965415000916\n",
      "8 300 loss: 0.469687283039093\n",
      "8 acc: 0.7483\n",
      "9 0 loss: 0.4554173946380615\n",
      "9 100 loss: 0.38359349966049194\n",
      "9 200 loss: 0.3470872640609741\n",
      "9 300 loss: 0.3842640519142151\n",
      "9 acc: 0.7472\n",
      "10 0 loss: 0.2686126232147217\n",
      "10 100 loss: 0.2994198799133301\n",
      "10 200 loss: 0.31323981285095215\n",
      "10 300 loss: 0.2277849167585373\n",
      "10 acc: 0.7671\n",
      "11 0 loss: 0.22210490703582764\n",
      "11 100 loss: 0.27492743730545044\n",
      "11 200 loss: 0.2084043025970459\n",
      "11 300 loss: 0.2738298177719116\n",
      "11 acc: 0.7712\n",
      "12 0 loss: 0.15003567934036255\n",
      "12 100 loss: 0.2942538261413574\n",
      "12 200 loss: 0.17954902350902557\n",
      "12 300 loss: 0.09651852399110794\n",
      "12 acc: 0.767\n",
      "13 0 loss: 0.10503745079040527\n",
      "13 100 loss: 0.13167378306388855\n",
      "13 200 loss: 0.19972485303878784\n",
      "13 300 loss: 0.12298113107681274\n",
      "13 acc: 0.7658\n",
      "14 0 loss: 0.09419380128383636\n",
      "14 100 loss: 0.054944902658462524\n",
      "14 200 loss: 0.06603486835956573\n",
      "14 300 loss: 0.055692724883556366\n",
      "14 acc: 0.7663\n",
      "15 0 loss: 0.05341200530529022\n",
      "15 100 loss: 0.1627839207649231\n",
      "15 200 loss: 0.08218777179718018\n",
      "15 300 loss: 0.08999177068471909\n",
      "15 acc: 0.7729\n",
      "16 0 loss: 0.06056966632604599\n",
      "16 100 loss: 0.0884772390127182\n",
      "16 200 loss: 0.06341291218996048\n",
      "16 300 loss: 0.06874527037143707\n",
      "16 acc: 0.7572\n",
      "17 0 loss: 0.16449999809265137\n",
      "17 100 loss: 0.0666409507393837\n",
      "17 200 loss: 0.08033955097198486\n",
      "17 300 loss: 0.07830411195755005\n",
      "17 acc: 0.7678\n",
      "18 0 loss: 0.09070219099521637\n",
      "18 100 loss: 0.067355215549469\n",
      "18 200 loss: 0.030073175206780434\n",
      "18 300 loss: 0.0327831506729126\n",
      "18 acc: 0.7678\n",
      "19 0 loss: 0.06778670847415924\n",
      "19 100 loss: 0.06237180531024933\n",
      "19 200 loss: 0.018225764855742455\n",
      "19 300 loss: 0.014427218586206436\n",
      "19 acc: 0.7717\n",
      "20 0 loss: 0.062427472323179245\n",
      "20 100 loss: 0.017035432159900665\n",
      "20 200 loss: 0.04990249127149582\n",
      "20 300 loss: 0.02856261469423771\n",
      "20 acc: 0.7712\n",
      "21 0 loss: 0.053656283766031265\n",
      "21 100 loss: 0.12048694491386414\n",
      "21 200 loss: 0.04593144357204437\n",
      "21 300 loss: 0.09148170799016953\n",
      "21 acc: 0.7651\n",
      "22 0 loss: 0.07975435256958008\n",
      "22 100 loss: 0.04027485474944115\n",
      "22 200 loss: 0.026120632886886597\n",
      "22 300 loss: 0.0849115252494812\n",
      "22 acc: 0.7796\n",
      "23 0 loss: 0.04502761363983154\n",
      "23 100 loss: 0.07192201912403107\n"
     ]
    }
   ],
   "source": [
    "import  tensorflow as tf\n",
    "from    tensorflow.keras import layers, optimizers, datasets, Sequential\n",
    "import  os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "tf.random.set_seed(2345)\n",
    "\n",
    "conv_layers = [ # 5 units of conv + max pooling\n",
    "    # unit 1\n",
    "    layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "\n",
    "    # unit 2\n",
    "    layers.Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "\n",
    "    # unit 3\n",
    "    layers.Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "\n",
    "    # unit 4\n",
    "    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "\n",
    "    # unit 5\n",
    "    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same')\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(x, y):\n",
    "    # [0~1]\n",
    "    x = 2*tf.cast(x, dtype=tf.float32) / 255.-1 # 把 x 轉成 -1到1之間\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x,y\n",
    "\n",
    "\n",
    "(x,y), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "y = tf.squeeze(y, axis=1)\n",
    "y_test = tf.squeeze(y_test, axis=1)\n",
    "print(x.shape, y.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "train_db = train_db.shuffle(1000).map(preprocess).batch(128)\n",
    "\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
    "test_db = test_db.map(preprocess).batch(64)\n",
    "\n",
    "sample = next(iter(train_db))\n",
    "print('sample:', sample[0].shape, sample[1].shape,\n",
    "      tf.reduce_min(sample[0]), tf.reduce_max(sample[0]))\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # [b, 32, 32, 3] => [b, 1, 1, 512]\n",
    "    conv_net = Sequential(conv_layers)\n",
    "\n",
    "    fc_net = Sequential([\n",
    "        layers.Dense(256, activation=tf.nn.relu),\n",
    "        layers.Dense(128, activation=tf.nn.relu),\n",
    "        layers.Dense(10, activation=None),\n",
    "    ])\n",
    "\n",
    "    conv_net.build(input_shape=[None, 32, 32, 3])\n",
    "    fc_net.build(input_shape=[None, 512])\n",
    "    conv_net.summary()\n",
    "    fc_net.summary()\n",
    "    optimizer = optimizers.Adam(lr=1e-4)\n",
    "\n",
    "    # [1, 2] + [3, 4] => [1, 2, 3, 4]\n",
    "    variables = conv_net.trainable_variables + fc_net.trainable_variables\n",
    "\n",
    "    for epoch in range(50):\n",
    "\n",
    "        for step, (x,y) in enumerate(train_db):\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                # [b, 32, 32, 3] => [b, 1, 1, 512]\n",
    "                out = conv_net(x)\n",
    "                # flatten, => [b, 512]\n",
    "                out = tf.reshape(out, [-1, 512])\n",
    "                # [b, 512] => [b, 10]\n",
    "                logits = fc_net(out)\n",
    "                # [b] => [b, 10]\n",
    "                y_onehot = tf.one_hot(y, depth=10)\n",
    "                # compute loss\n",
    "                loss = tf.losses.categorical_crossentropy(y_onehot, logits, from_logits=True)\n",
    "                loss = tf.reduce_mean(loss)\n",
    "\n",
    "            grads = tape.gradient(loss, variables)\n",
    "            optimizer.apply_gradients(zip(grads, variables))\n",
    "\n",
    "            if step %100 == 0:\n",
    "                print(epoch, step, 'loss:', float(loss))\n",
    "\n",
    "\n",
    "\n",
    "        total_num = 0\n",
    "        total_correct = 0\n",
    "        for x,y in test_db:\n",
    "\n",
    "            out = conv_net(x)\n",
    "            out = tf.reshape(out, [-1, 512])\n",
    "            logits = fc_net(out)\n",
    "            prob = tf.nn.softmax(logits, axis=1)\n",
    "            pred = tf.argmax(prob, axis=1)\n",
    "            pred = tf.cast(pred, dtype=tf.int32)\n",
    "\n",
    "            correct = tf.cast(tf.equal(pred, y), dtype=tf.int32)\n",
    "            correct = tf.reduce_sum(correct)\n",
    "\n",
    "            total_num += x.shape[0]\n",
    "            total_correct += int(correct)\n",
    "\n",
    "        acc = total_correct / total_num\n",
    "        print(epoch, 'acc:', acc)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97ohV-2Q1ZI3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Demo12_tf2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
