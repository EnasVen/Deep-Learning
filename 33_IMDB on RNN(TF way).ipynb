{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB(TensorFlow版本)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, SimpleRNN\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "\n",
    "total_words = 10000\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_review_len = 80\n",
    "# x_train:[b, 80]\n",
    "# x_test: [b, 80]\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  15,  256,    4,    2,    7, 3766,    5,  723,   36,   71,   43,\n",
       "         530,  476,   26,  400,  317,   46,    7,    4,    2, 1029,   13,\n",
       "         104,   88,    4,  381,   15,  297,   98,   32, 2071,   56,   26,\n",
       "         141,    6,  194, 7486,   18,    4,  226,   22,   21,  134,  476,\n",
       "          26,  480,    5,  144,   30, 5535,   18,   51,   36,   28,  224,\n",
       "          92,   25,  104,    4,  226,   65,   16,   38, 1334,   88,   12,\n",
       "          16,  283,    5,   16, 4472,  113,  103,   32,   15,   16, 5345,\n",
       "          19,  178,   32],\n",
       "       [ 125,   68,    2, 6853,   15,  349,  165, 4362,   98,    5,    4,\n",
       "         228,    9,   43,    2, 1157,   15,  299,  120,    5,  120,  174,\n",
       "          11,  220,  175,  136,   50,    9, 4373,  228, 8255,    5,    2,\n",
       "         656,  245, 2350,    5,    4, 9837,  131,  152,  491,   18,    2,\n",
       "          32, 7464, 1212,   14,    9,    6,  371,   78,   22,  625,   64,\n",
       "        1382,    9,    8,  168,  145,   23,    4, 1690,   15,   16,    4,\n",
       "        1355,    5,   28,    6,   52,  154,  462,   33,   89,   78,  285,\n",
       "          16,  145,   95],\n",
       "       [ 645,  662,    8,  257,   85, 1200,   42, 1228, 2578,   83,   68,\n",
       "        3912,   15,   36,  165, 1539,  278,   36,   69,    2,  780,    8,\n",
       "         106,   14, 6905, 1338,   18,    6,   22,   12,  215,   28,  610,\n",
       "          40,    6,   87,  326,   23, 2300,   21,   23,   22,   12,  272,\n",
       "          40,   57,   31,   11,    4,   22,   47,    6, 2307,   51,    9,\n",
       "         170,   23,  595,  116,  595, 1352,   13,  191,   79,  638,   89,\n",
       "           2,   14,    9,    8,  106,  607,  624,   35,  534,    6,  227,\n",
       "           7,  129,  113],\n",
       "       [   2,   14,  280,   13,  219,    4,    2,  431,  758,  859,    4,\n",
       "         953, 1052,    2,    7, 5991,    5,   94,   40,   25,  238,   60,\n",
       "           2,    4,    2,  804,    2,    7,    4, 9941,  132,    8,   67,\n",
       "           6,   22,   15,    9,  283,    8, 5168,   14,   31,    9,  242,\n",
       "         955,   48,   25,  279,    2,   23,   12, 1685,  195,   25,  238,\n",
       "          60,  796,    2,    4,  671,    7, 2804,    5,    4,  559,  154,\n",
       "         888,    7,  726,   50,   26,   49, 7008,   15,  566,   30,  579,\n",
       "          21,   64, 2574],\n",
       "       [  56,  429,    6, 1513,   18,   35,  534,   95,  474,  570,    5,\n",
       "          25,  124,  138,   88,   12,  421, 1543,   52,  725, 6397,   61,\n",
       "         419,   11,   13, 1571,   15, 1543,   20,   11,    4,    2,    5,\n",
       "         296,   12, 3524,    5,   15,  421,  128,   74,  233,  334,  207,\n",
       "         126,  224,   12,  562,  298, 2167, 1272,    7, 2601,    5,  516,\n",
       "         988,   43,    8,   79,  120,   15,  595,   13,  784,   25, 3171,\n",
       "          18,  165,  170,  143,   19,   14,    5, 7224,    6,  226,  251,\n",
       "           7,   61,  113]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "db_train = db_train.shuffle(1000).batch(batch_size, drop_remainder=True)\n",
    "db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "db_test = db_test.batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_len =32\n",
    "\n",
    "class MyRNN(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, units):\n",
    "        super(MyRNN, self).__init__()\n",
    "\n",
    "        # [b, 64]\n",
    "        self.state = [tf.zeros([batch_size, units])]\n",
    "        # self.state1 = [tf.zeros([batchsz, units])]\n",
    "        # transform text to embedding representation\n",
    "        # [b, 80] => [b, 80, 32]\n",
    "        self.embedding = tf.keras.layers.Embedding(total_words, embedding_len,\n",
    "                                          input_length=max_review_len)\n",
    "        # [b, 80, 32] , h_dim: 64\n",
    "        # RNN: cell1 ,cell2, cell3\n",
    "        # SimpleRNN\n",
    "        self.rnn_cell = tf.keras.layers.SimpleRNNCell(units, dropout=0.2)\n",
    "        # self.rnn_cell1 = layers.SimpleRNNCell(units, dropout=0.5)\n",
    "        # fc, [b, 80, 32] => [b, 64] => [b, 1]\n",
    "        self.fc= tf.keras.layers.Dense(1) # 二元分類也可以輸出層只給1個神經元，但後面的loss要用binary_cross_entropy\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # [b, 80]\n",
    "        x = inputs\n",
    "        # embedding: [b, 80] => [b, 80, 32]\n",
    "        x = self.embedding(x)\n",
    "        # rnn cell compute\n",
    "        # [b, 80, 32] => [b, 64]\n",
    "        state = self.state\n",
    "        # state1 = self.state1\n",
    "        for word in tf.unstack(x, axis=1): # word: [b, 32]\n",
    "            # h1 = x*wxh+h0*whh\n",
    "            # out: [b, 64]\n",
    "            out, state = self.rnn_cell(word, state, training)\n",
    "        # out: [b, 64] => [b, 1]\n",
    "        x = self.fc(out)\n",
    "        # p(y is pos|x)\n",
    "        prob = tf.sigmoid(x)\n",
    "\n",
    "        return prob\n",
    "\n",
    "model = MyRNN(64) \n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "781/781 [==============================] - 4s 5ms/step - loss: 0.5939 - accuracy: 0.6612 - val_loss: 0.4388 - val_accuracy: 0.8050\n",
      "Epoch 2/5\n",
      "781/781 [==============================] - 3s 4ms/step - loss: 0.3700 - accuracy: 0.8389 - val_loss: 0.4240 - val_accuracy: 0.8220\n",
      "Epoch 3/5\n",
      "781/781 [==============================] - 3s 4ms/step - loss: 0.2639 - accuracy: 0.8932 - val_loss: 0.4769 - val_accuracy: 0.8154\n",
      "Epoch 4/5\n",
      "781/781 [==============================] - 4s 5ms/step - loss: 0.1814 - accuracy: 0.9309 - val_loss: 0.5956 - val_accuracy: 0.7567\n",
      "Epoch 5/5\n",
      "781/781 [==============================] - 3s 4ms/step - loss: 0.1196 - accuracy: 0.9554 - val_loss: 0.6436 - val_accuracy: 0.7958\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(db_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=512,\n",
    "                    validation_data=db_test,\n",
    "                    verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
